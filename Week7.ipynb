{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\1\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage1 = pd.DataFrame(comb_np_array)\n",
    "task_usage1.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            start time      end time        job ID\n",
      "0         6.000000e+08  9.000000e+08  3.418314e+06\n",
      "1         6.000000e+08  9.000000e+08  3.418314e+06\n",
      "2         6.000000e+08  9.000000e+08  3.418319e+06\n",
      "3         6.000000e+08  9.000000e+08  3.418319e+06\n",
      "4         6.000000e+08  9.000000e+08  3.418324e+06\n",
      "...                ...           ...           ...\n",
      "54381808  1.008230e+11  1.009230e+11  6.260707e+09\n",
      "54381809  1.008230e+11  1.010570e+11  6.260707e+09\n",
      "54381810  1.008230e+11  1.008530e+11  6.260716e+09\n",
      "54381811  1.008230e+11  1.008530e+11  6.260716e+09\n",
      "54381812  1.008230e+11  1.008900e+11  6.260716e+09\n",
      "\n",
      "[54381813 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print (task_usage1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage1 = task_usage1.groupby('job ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage_1 = task_usage1.agg({'start time': ['min'], 'end time':['max']}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                start time      end time\n",
      "                       min           max\n",
      "job ID                                  \n",
      "3.418309e+06  9.000000e+08  1.011000e+11\n",
      "3.418314e+06  6.000000e+08  1.011000e+11\n",
      "3.418319e+06  6.000000e+08  1.011000e+11\n",
      "3.418324e+06  6.000000e+08  1.011000e+11\n",
      "3.418329e+06  6.000000e+08  1.011000e+11\n",
      "...                    ...           ...\n",
      "6.260707e+09  1.008130e+11  1.011000e+11\n",
      "6.260715e+09  1.008150e+11  1.008650e+11\n",
      "6.260716e+09  1.007920e+11  1.009920e+11\n",
      "6.260716e+09  1.008000e+11  1.008330e+11\n",
      "6.260717e+09  1.008170e+11  1.008480e+11\n",
      "\n",
      "[26517 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print (task_usage_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage_1a = task_usage_1.reset_index()[['job ID', 'start time', 'end time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  9.000000e+08  1.011000e+11\n",
      "1      3.418314e+06  6.000000e+08  1.011000e+11\n",
      "2      3.418319e+06  6.000000e+08  1.011000e+11\n",
      "3      3.418324e+06  6.000000e+08  1.011000e+11\n",
      "4      3.418329e+06  6.000000e+08  1.011000e+11\n",
      "...             ...           ...           ...\n",
      "26512  6.260707e+09  1.008130e+11  1.011000e+11\n",
      "26513  6.260715e+09  1.008150e+11  1.008650e+11\n",
      "26514  6.260716e+09  1.007920e+11  1.009920e+11\n",
      "26515  6.260716e+09  1.008000e+11  1.008330e+11\n",
      "26516  6.260717e+09  1.008170e+11  1.008480e+11\n",
      "\n",
      "[26517 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print (task_usage_1a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage_1a.to_csv(\"task_usage_jobonly_1.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\2\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage2 = pd.DataFrame(comb_np_array)\n",
    "task_usage2.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.011000e+11  2.013000e+11\n",
      "1      3.418314e+06  1.011000e+11  2.013000e+11\n",
      "2      3.418319e+06  1.011000e+11  2.013000e+11\n",
      "3      3.418324e+06  1.011000e+11  2.013000e+11\n",
      "4      3.418329e+06  1.011000e+11  2.013000e+11\n",
      "...             ...           ...           ...\n",
      "30258  6.276748e+09  2.010420e+11  2.010550e+11\n",
      "30259  6.276748e+09  2.010310e+11  2.013000e+11\n",
      "30260  6.276748e+09  2.010370e+11  2.010500e+11\n",
      "30261  6.276750e+09  2.010440e+11  2.010850e+11\n",
      "30262  6.276750e+09  2.010450e+11  2.010880e+11\n",
      "\n",
      "[30263 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage2 = task_usage2.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage2 = task_usage2.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage2.to_csv(\"task_usage_jobonly_2.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\3\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage3 = pd.DataFrame(comb_np_array)\n",
    "task_usage3.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  2.013000e+11  3.015000e+11\n",
      "1      3.418314e+06  2.013000e+11  3.015000e+11\n",
      "2      3.418319e+06  2.013000e+11  3.015000e+11\n",
      "3      3.418324e+06  2.013000e+11  3.015000e+11\n",
      "4      3.418329e+06  2.013000e+11  3.015000e+11\n",
      "...             ...           ...           ...\n",
      "26277  6.286124e+09  3.012530e+11  3.012800e+11\n",
      "26278  6.286124e+09  3.012530e+11  3.012800e+11\n",
      "26279  6.286124e+09  3.012600e+11  3.013220e+11\n",
      "26280  6.286124e+09  3.012630e+11  3.012990e+11\n",
      "26281  6.286124e+09  3.012620e+11  3.012840e+11\n",
      "\n",
      "[26282 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage3 = task_usage3.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage3 = task_usage3.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage3.to_csv(\"task_usage_jobonly_3.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\4\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage4 = pd.DataFrame(comb_np_array)\n",
    "task_usage4.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  3.015000e+11  4.017000e+11\n",
      "1      3.418314e+06  3.015000e+11  4.017000e+11\n",
      "2      3.418319e+06  3.015000e+11  4.017000e+11\n",
      "3      3.418324e+06  3.015000e+11  4.017000e+11\n",
      "4      3.418329e+06  3.015000e+11  4.017000e+11\n",
      "...             ...           ...           ...\n",
      "28290  6.293388e+09  4.014610e+11  4.016900e+11\n",
      "28291  6.293388e+09  4.014540e+11  4.016910e+11\n",
      "28292  6.293389e+09  4.014610e+11  4.017000e+11\n",
      "28293  6.293389e+09  4.014580e+11  4.017000e+11\n",
      "28294  6.293389e+09  4.014690e+11  4.014930e+11\n",
      "\n",
      "[28295 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage4 = task_usage4.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage4 = task_usage4.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage4.to_csv(\"task_usage_jobonly_4.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\5\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage5 = pd.DataFrame(comb_np_array)\n",
    "task_usage5.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  4.017000e+11  5.019000e+11\n",
      "1      3.418314e+06  4.017000e+11  5.019000e+11\n",
      "2      3.418319e+06  4.017000e+11  5.019000e+11\n",
      "3      3.418324e+06  4.017000e+11  5.019000e+11\n",
      "4      3.418329e+06  4.017000e+11  5.019000e+11\n",
      "...             ...           ...           ...\n",
      "31282  6.300425e+09  5.017100e+11  5.017380e+11\n",
      "31283  6.300425e+09  5.017130e+11  5.017330e+11\n",
      "31284  6.300427e+09  5.017130e+11  5.017330e+11\n",
      "31285  6.300427e+09  5.017160e+11  5.019000e+11\n",
      "31286  6.300427e+09  5.017160e+11  5.017660e+11\n",
      "\n",
      "[31287 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage5 = task_usage5.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage5 = task_usage5.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage5.to_csv(\"task_usage_jobonly_5.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\6\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage6 = pd.DataFrame(comb_np_array)\n",
    "task_usage6.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  5.019000e+11  6.021000e+11\n",
      "1      3.418314e+06  5.019000e+11  6.021000e+11\n",
      "2      3.418319e+06  5.019000e+11  6.021000e+11\n",
      "3      3.418324e+06  5.019000e+11  6.021000e+11\n",
      "4      3.418329e+06  5.019000e+11  6.021000e+11\n",
      "...             ...           ...           ...\n",
      "24344  6.306073e+09  6.018680e+11  6.020030e+11\n",
      "24345  6.306074e+09  6.018950e+11  6.019290e+11\n",
      "24346  6.306076e+09  6.019130e+11  6.020640e+11\n",
      "24347  6.306076e+09  6.019070e+11  6.020650e+11\n",
      "24348  6.306076e+09  6.019060e+11  6.020850e+11\n",
      "\n",
      "[24349 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage6 = task_usage6.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage6 = task_usage6.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage6.to_csv(\"task_usage_jobonly_6.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\7\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage7 = pd.DataFrame(comb_np_array)\n",
    "task_usage7.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  6.021000e+11  7.023000e+11\n",
      "1      3.418314e+06  6.021000e+11  7.023000e+11\n",
      "2      3.418319e+06  6.021000e+11  7.023000e+11\n",
      "3      3.418324e+06  6.021000e+11  7.023000e+11\n",
      "4      3.418329e+06  6.021000e+11  7.023000e+11\n",
      "...             ...           ...           ...\n",
      "28939  6.313919e+09  7.021460e+11  7.023000e+11\n",
      "28940  6.313919e+09  7.021570e+11  7.021810e+11\n",
      "28941  6.313919e+09  7.021430e+11  7.022390e+11\n",
      "28942  6.313920e+09  7.021520e+11  7.023000e+11\n",
      "28943  6.313920e+09  7.021610e+11  7.022030e+11\n",
      "\n",
      "[28944 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage7 = task_usage7.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage7 = task_usage7.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage7.to_csv(\"task_usage_jobonly_7.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\8\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage8 = pd.DataFrame(comb_np_array)\n",
    "task_usage8.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  7.023000e+11  8.025000e+11\n",
      "1      3.418314e+06  7.023000e+11  8.025000e+11\n",
      "2      3.418319e+06  7.023000e+11  8.025000e+11\n",
      "3      3.418324e+06  7.023000e+11  8.025000e+11\n",
      "4      3.418329e+06  7.023000e+11  8.025000e+11\n",
      "...             ...           ...           ...\n",
      "30899  6.324474e+09  8.023080e+11  8.023250e+11\n",
      "30900  6.324477e+09  8.023530e+11  8.023750e+11\n",
      "30901  6.324477e+09  8.023510e+11  8.023780e+11\n",
      "30902  6.324477e+09  8.023430e+11  8.025000e+11\n",
      "30903  6.324479e+09  8.023890e+11  8.023990e+11\n",
      "\n",
      "[30904 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage8 = task_usage8.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage8 = task_usage8.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage8.to_csv(\"task_usage_jobonly_8.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\9\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage9 = pd.DataFrame(comb_np_array)\n",
    "task_usage9.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  8.025000e+11  9.027000e+11\n",
      "1      3.418314e+06  8.025000e+11  9.027000e+11\n",
      "2      3.418319e+06  8.025000e+11  9.027000e+11\n",
      "3      3.418324e+06  8.025000e+11  9.027000e+11\n",
      "4      3.418329e+06  8.025000e+11  9.027000e+11\n",
      "...             ...           ...           ...\n",
      "31472  6.340062e+09  9.025940e+11  9.027000e+11\n",
      "31473  6.340063e+09  9.025770e+11  9.027000e+11\n",
      "31474  6.340063e+09  9.025880e+11  9.027000e+11\n",
      "31475  6.340069e+09  9.026140e+11  9.026600e+11\n",
      "31476  6.340070e+09  9.026070e+11  9.026600e+11\n",
      "\n",
      "[31477 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage9 = task_usage9.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage9 = task_usage9.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage9.to_csv(\"task_usage_jobonly_9.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\10\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage10 = pd.DataFrame(comb_np_array)\n",
    "task_usage10.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  9.027000e+11  1.002900e+12\n",
      "1      3.418314e+06  9.027000e+11  1.002900e+12\n",
      "2      3.418319e+06  9.027000e+11  1.002900e+12\n",
      "3      3.418324e+06  9.027000e+11  1.002900e+12\n",
      "4      3.418329e+06  9.027000e+11  1.002900e+12\n",
      "...             ...           ...           ...\n",
      "30266  6.350360e+09  1.002831e+12  1.002882e+12\n",
      "30267  6.350360e+09  1.002828e+12  1.002858e+12\n",
      "30268  6.350360e+09  1.002836e+12  1.002900e+12\n",
      "30269  6.350360e+09  1.002835e+12  1.002900e+12\n",
      "30270  6.350360e+09  1.002838e+12  1.002853e+12\n",
      "\n",
      "[30271 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage10 = task_usage10.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage10 = task_usage10.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage10.to_csv(\"task_usage_jobonly_10.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\11\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage11 = pd.DataFrame(comb_np_array)\n",
    "task_usage11.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.002900e+12  1.103100e+12\n",
      "1      3.418314e+06  1.002900e+12  1.103100e+12\n",
      "2      3.418319e+06  1.002900e+12  1.103100e+12\n",
      "3      3.418324e+06  1.002900e+12  1.103100e+12\n",
      "4      3.418329e+06  1.002900e+12  1.103100e+12\n",
      "...             ...           ...           ...\n",
      "30180  6.358021e+09  1.103016e+12  1.103100e+12\n",
      "30181  6.358022e+09  1.103020e+12  1.103100e+12\n",
      "30182  6.358022e+09  1.103026e+12  1.103100e+12\n",
      "30183  6.358022e+09  1.103026e+12  1.103100e+12\n",
      "30184  6.358024e+09  1.103059e+12  1.103072e+12\n",
      "\n",
      "[30185 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage11 = task_usage11.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage11 = task_usage11.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage11.to_csv(\"task_usage_jobonly_11.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\12\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage12 = pd.DataFrame(comb_np_array)\n",
    "task_usage12.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.103100e+12  1.203300e+12\n",
      "1      3.418314e+06  1.103100e+12  1.203300e+12\n",
      "2      3.418319e+06  1.103100e+12  1.203300e+12\n",
      "3      3.418324e+06  1.103100e+12  1.203300e+12\n",
      "4      3.418329e+06  1.103100e+12  1.203300e+12\n",
      "...             ...           ...           ...\n",
      "21693  6.363906e+09  1.203273e+12  1.203288e+12\n",
      "21694  6.363906e+09  1.203281e+12  1.203300e+12\n",
      "21695  6.363906e+09  1.203275e+12  1.203300e+12\n",
      "21696  6.363906e+09  1.203280e+12  1.203300e+12\n",
      "21697  6.363907e+09  1.203287e+12  1.203290e+12\n",
      "\n",
      "[21698 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage12 = task_usage12.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage12 = task_usage12.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage12.to_csv(\"task_usage_jobonly_12.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\13\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage13 = pd.DataFrame(comb_np_array)\n",
    "task_usage13.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.203300e+12  1.303800e+12\n",
      "1      3.418314e+06  1.203300e+12  1.303800e+12\n",
      "2      3.418319e+06  1.203300e+12  1.303800e+12\n",
      "3      3.418324e+06  1.203300e+12  1.303800e+12\n",
      "4      3.418329e+06  1.203300e+12  1.303800e+12\n",
      "...             ...           ...           ...\n",
      "27237  6.372291e+09  1.303500e+12  1.303613e+12\n",
      "27238  6.372292e+09  1.303481e+12  1.303680e+12\n",
      "27239  6.372292e+09  1.303503e+12  1.303569e+12\n",
      "27240  6.372292e+09  1.303482e+12  1.303800e+12\n",
      "27241  6.372292e+09  1.303508e+12  1.303532e+12\n",
      "\n",
      "[27242 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage13 = task_usage13.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage13 = task_usage13.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage13.to_csv(\"task_usage_jobonly_13.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\14\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage14 = pd.DataFrame(comb_np_array)\n",
    "task_usage14.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.303800e+12  1.404000e+12\n",
      "1      3.418314e+06  1.303800e+12  1.404000e+12\n",
      "2      3.418319e+06  1.303800e+12  1.404000e+12\n",
      "3      3.418324e+06  1.303800e+12  1.404000e+12\n",
      "4      3.418329e+06  1.303800e+12  1.404000e+12\n",
      "...             ...           ...           ...\n",
      "32121  6.381426e+09  1.403726e+12  1.403746e+12\n",
      "32122  6.381426e+09  1.403723e+12  1.403752e+12\n",
      "32123  6.381426e+09  1.403712e+12  1.403846e+12\n",
      "32124  6.381426e+09  1.403719e+12  1.403742e+12\n",
      "32125  6.381426e+09  1.403720e+12  1.404000e+12\n",
      "\n",
      "[32126 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage14 = task_usage14.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage14 = task_usage14.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage14.to_csv(\"task_usage_jobonly_14.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\15\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage15 = pd.DataFrame(comb_np_array)\n",
    "task_usage15.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.404000e+12  1.504200e+12\n",
      "1      3.418314e+06  1.404000e+12  1.504200e+12\n",
      "2      3.418319e+06  1.404000e+12  1.504200e+12\n",
      "3      3.418324e+06  1.404000e+12  1.504200e+12\n",
      "4      3.418329e+06  1.404000e+12  1.504200e+12\n",
      "...             ...           ...           ...\n",
      "39648  6.392687e+09  1.503949e+12  1.503975e+12\n",
      "39649  6.392687e+09  1.503951e+12  1.503973e+12\n",
      "39650  6.392688e+09  1.503957e+12  1.503982e+12\n",
      "39651  6.392688e+09  1.503952e+12  1.504061e+12\n",
      "39652  6.392688e+09  1.503945e+12  1.504044e+12\n",
      "\n",
      "[39653 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage15 = task_usage15.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage15 = task_usage15.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage15.to_csv(\"task_usage_jobonly_15.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\16\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage16 = pd.DataFrame(comb_np_array)\n",
    "task_usage16.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.504200e+12  1.604400e+12\n",
      "1      3.418314e+06  1.504200e+12  1.604400e+12\n",
      "2      3.418319e+06  1.504200e+12  1.604400e+12\n",
      "3      3.418324e+06  1.504200e+12  1.604400e+12\n",
      "4      3.418329e+06  1.504200e+12  1.604400e+12\n",
      "...             ...           ...           ...\n",
      "43890  6.404437e+09  1.604133e+12  1.604387e+12\n",
      "43891  6.404438e+09  1.604129e+12  1.604143e+12\n",
      "43892  6.404439e+09  1.604159e+12  1.604174e+12\n",
      "43893  6.404439e+09  1.604171e+12  1.604192e+12\n",
      "43894  6.404439e+09  1.604166e+12  1.604181e+12\n",
      "\n",
      "[43895 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage16 = task_usage16.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage16 = task_usage16.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage16.to_csv(\"task_usage_jobonly_16.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\17\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage17 = pd.DataFrame(comb_np_array)\n",
    "task_usage17.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.604400e+12  1.704600e+12\n",
      "1      3.418314e+06  1.604400e+12  1.704600e+12\n",
      "2      3.418319e+06  1.604400e+12  1.704600e+12\n",
      "3      3.418324e+06  1.604400e+12  1.704600e+12\n",
      "4      3.418329e+06  1.604400e+12  1.704600e+12\n",
      "...             ...           ...           ...\n",
      "33419  6.413707e+09  1.704393e+12  1.704562e+12\n",
      "33420  6.413707e+09  1.704405e+12  1.704600e+12\n",
      "33421  6.413707e+09  1.704394e+12  1.704600e+12\n",
      "33422  6.413711e+09  1.704407e+12  1.704428e+12\n",
      "33423  6.413711e+09  1.704401e+12  1.704441e+12\n",
      "\n",
      "[33424 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage17 = task_usage17.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage17 = task_usage17.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage17.to_csv(\"task_usage_jobonly_17.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\18\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage18 = pd.DataFrame(comb_np_array)\n",
    "task_usage18.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.704600e+12  1.804800e+12\n",
      "1      3.418314e+06  1.704600e+12  1.804800e+12\n",
      "2      3.418319e+06  1.704600e+12  1.804800e+12\n",
      "3      3.418324e+06  1.704600e+12  1.804800e+12\n",
      "4      3.418329e+06  1.704600e+12  1.804800e+12\n",
      "...             ...           ...           ...\n",
      "25406  6.419867e+09  1.804599e+12  1.804800e+12\n",
      "25407  6.419867e+09  1.804596e+12  1.804800e+12\n",
      "25408  6.419867e+09  1.804604e+12  1.804800e+12\n",
      "25409  6.419867e+09  1.804612e+12  1.804622e+12\n",
      "25410  6.419867e+09  1.804626e+12  1.804636e+12\n",
      "\n",
      "[25411 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage18 = task_usage18.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage18 = task_usage18.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage18.to_csv(\"task_usage_jobonly_18.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\19\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage19 = pd.DataFrame(comb_np_array)\n",
    "task_usage19.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.804800e+12  1.905000e+12\n",
      "1      3.418314e+06  1.804800e+12  1.905000e+12\n",
      "2      3.418319e+06  1.804800e+12  1.905000e+12\n",
      "3      3.418324e+06  1.804800e+12  1.905000e+12\n",
      "4      3.418329e+06  1.804800e+12  1.905000e+12\n",
      "...             ...           ...           ...\n",
      "28376  6.427948e+09  1.904784e+12  1.905000e+12\n",
      "28377  6.427955e+09  1.904801e+12  1.905000e+12\n",
      "28378  6.427960e+09  1.904812e+12  1.904830e+12\n",
      "28379  6.427961e+09  1.904845e+12  1.904865e+12\n",
      "28380  6.427961e+09  1.904845e+12  1.904868e+12\n",
      "\n",
      "[28381 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage19 = task_usage19.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage19 = task_usage19.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage19.to_csv(\"task_usage_jobonly_19.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\20\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage20 = pd.DataFrame(comb_np_array)\n",
    "task_usage20.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  1.905000e+12  2.005200e+12\n",
      "1      3.418314e+06  1.905000e+12  2.005200e+12\n",
      "2      3.418319e+06  1.905000e+12  2.005200e+12\n",
      "3      3.418324e+06  1.905000e+12  2.005200e+12\n",
      "4      3.418329e+06  1.905000e+12  2.005200e+12\n",
      "...             ...           ...           ...\n",
      "33219  6.439426e+09  2.005036e+12  2.005200e+12\n",
      "33220  6.439427e+09  2.005027e+12  2.005200e+12\n",
      "33221  6.439428e+09  2.005033e+12  2.005049e+12\n",
      "33222  6.439428e+09  2.005047e+12  2.005078e+12\n",
      "33223  6.439432e+09  2.005059e+12  2.005075e+12\n",
      "\n",
      "[33224 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage20 = task_usage20.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage20 = task_usage20.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage20.to_csv(\"task_usage_jobonly_20.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\21\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage21 = pd.DataFrame(comb_np_array)\n",
    "task_usage21.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  2.005200e+12  2.105400e+12\n",
      "1      3.418314e+06  2.005200e+12  2.105400e+12\n",
      "2      3.418319e+06  2.005200e+12  2.105400e+12\n",
      "3      3.418324e+06  2.005200e+12  2.105400e+12\n",
      "4      3.418329e+06  2.005200e+12  2.105400e+12\n",
      "...             ...           ...           ...\n",
      "29786  6.449379e+09  2.105245e+12  2.105262e+12\n",
      "29787  6.449380e+09  2.105260e+12  2.105303e+12\n",
      "29788  6.449380e+09  2.105260e+12  2.105330e+12\n",
      "29789  6.449386e+09  2.105281e+12  2.105400e+12\n",
      "29790  6.449386e+09  2.105294e+12  2.105400e+12\n",
      "\n",
      "[29791 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage21 = task_usage21.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage21 = task_usage21.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage21.to_csv(\"task_usage_jobonly_21.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\22\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage22 = pd.DataFrame(comb_np_array)\n",
    "task_usage22.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  2.105400e+12  2.205600e+12\n",
      "1      3.418314e+06  2.105400e+12  2.205600e+12\n",
      "2      3.418319e+06  2.105400e+12  2.205600e+12\n",
      "3      3.418324e+06  2.105400e+12  2.205600e+12\n",
      "4      3.418329e+06  2.105400e+12  2.205600e+12\n",
      "...             ...           ...           ...\n",
      "30724  6.459274e+09  2.205488e+12  2.205600e+12\n",
      "30725  6.459274e+09  2.205509e+12  2.205535e+12\n",
      "30726  6.459274e+09  2.205488e+12  2.205600e+12\n",
      "30727  6.459274e+09  2.205500e+12  2.205600e+12\n",
      "30728  6.459274e+09  2.205506e+12  2.205521e+12\n",
      "\n",
      "[30729 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage22 = task_usage22.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage22 = task_usage22.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage22.to_csv(\"task_usage_jobonly_22.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\23\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage23 = pd.DataFrame(comb_np_array)\n",
    "task_usage23.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  2.205600e+12  2.305800e+12\n",
      "1      3.418314e+06  2.205600e+12  2.305800e+12\n",
      "2      3.418319e+06  2.205600e+12  2.305800e+12\n",
      "3      3.418324e+06  2.205600e+12  2.305800e+12\n",
      "4      3.418329e+06  2.205600e+12  2.305800e+12\n",
      "...             ...           ...           ...\n",
      "33589  6.469163e+09  2.305733e+12  2.305789e+12\n",
      "33590  6.469163e+09  2.305700e+12  2.305722e+12\n",
      "33591  6.469163e+09  2.305702e+12  2.305722e+12\n",
      "33592  6.469186e+09  2.305751e+12  2.305793e+12\n",
      "33593  6.469186e+09  2.305750e+12  2.305799e+12\n",
      "\n",
      "[33594 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage23 = task_usage23.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage23 = task_usage23.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage23.to_csv(\"task_usage_jobonly_23.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\24\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage24 = pd.DataFrame(comb_np_array)\n",
    "task_usage24.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  2.305800e+12  2.406000e+12\n",
      "1      3.418314e+06  2.305800e+12  2.406000e+12\n",
      "2      3.418319e+06  2.305800e+12  2.406000e+12\n",
      "3      3.418324e+06  2.305800e+12  2.406000e+12\n",
      "4      3.418329e+06  2.305800e+12  2.406000e+12\n",
      "...             ...           ...           ...\n",
      "28182  6.477730e+09  2.405970e+12  2.406000e+12\n",
      "28183  6.477730e+09  2.405975e+12  2.406000e+12\n",
      "28184  6.477730e+09  2.405966e+12  2.405980e+12\n",
      "28185  6.477730e+09  2.405969e+12  2.405981e+12\n",
      "28186  6.477730e+09  2.405975e+12  2.406000e+12\n",
      "\n",
      "[28187 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage24 = task_usage24.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage24 = task_usage24.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage24.to_csv(\"task_usage_jobonly_24.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\\25\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, skiprows=1, usecols = [1,2,3])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage25 = pd.DataFrame(comb_np_array)\n",
    "task_usage25.columns = ['start time', 'end time', 'job ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID    start time      end time\n",
      "                              min           max\n",
      "0      3.418309e+06  2.406000e+12  2.506200e+12\n",
      "1      3.418314e+06  2.406000e+12  2.506200e+12\n",
      "2      3.418319e+06  2.406000e+12  2.506200e+12\n",
      "3      3.418324e+06  2.406000e+12  2.506200e+12\n",
      "4      3.418329e+06  2.406000e+12  2.506200e+12\n",
      "...             ...           ...           ...\n",
      "23567  6.486634e+09  2.506141e+12  2.506178e+12\n",
      "23568  6.486634e+09  2.506145e+12  2.506182e+12\n",
      "23569  6.486638e+09  2.506149e+12  2.506187e+12\n",
      "23570  6.486638e+09  2.506155e+12  2.506200e+12\n",
      "23571  6.486641e+09  2.506185e+12  2.506200e+12\n",
      "\n",
      "[23572 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage25 = task_usage25.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage25 = task_usage25.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage25.to_csv(\"task_usage_jobonly_25.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge all task_usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0)\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_usage_jobonly = pd.DataFrame(comb_np_array)\n",
    "task_usage_jobonly.columns = ['job ID','start time', 'end time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              job ID    start time      end time\n",
      "0       3.418314e+06  6.000000e+08  1.011000e+11\n",
      "1       3.418319e+06  6.000000e+08  1.011000e+11\n",
      "2       3.418324e+06  6.000000e+08  1.011000e+11\n",
      "3       3.418329e+06  6.000000e+08  1.011000e+11\n",
      "4       3.418334e+06  6.000000e+08  1.011000e+11\n",
      "...              ...           ...           ...\n",
      "749671  6.340062e+09  9.025940e+11  9.027000e+11\n",
      "749672  6.340063e+09  9.025770e+11  9.027000e+11\n",
      "749673  6.340063e+09  9.025880e+11  9.027000e+11\n",
      "749674  6.340069e+09  9.026140e+11  9.026600e+11\n",
      "749675  6.340070e+09  9.026070e+11  9.026600e+11\n",
      "\n",
      "[749676 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print (task_usage_jobonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              job ID    start time      end time\n",
      "                               min           max\n",
      "0       3.418314e+06  6.000000e+08  2.506200e+12\n",
      "1       3.418319e+06  6.000000e+08  2.506200e+12\n",
      "2       3.418324e+06  6.000000e+08  2.506200e+12\n",
      "3       3.418329e+06  6.000000e+08  2.506200e+12\n",
      "4       3.418334e+06  6.000000e+08  2.506200e+12\n",
      "...              ...           ...           ...\n",
      "651555  6.486634e+09  2.506141e+12  2.506178e+12\n",
      "651556  6.486634e+09  2.506145e+12  2.506182e+12\n",
      "651557  6.486638e+09  2.506149e+12  2.506187e+12\n",
      "651558  6.486638e+09  2.506155e+12  2.506200e+12\n",
      "651559  6.486641e+09  2.506185e+12  2.506200e+12\n",
      "\n",
      "[651560 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "task_usage_jobonly1 = task_usage_jobonly.groupby('job ID').agg({'start time': ['min'], 'end time':['max']}) \n",
    "task_usage_jobonly2 = task_usage_jobonly1.reset_index()[['job ID', 'start time', 'end time']]\n",
    "print (task_usage_jobonly2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_usage_jobonly2.to_csv(\"task_usage_jobonly.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuj = pd.read_csv (r'C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage_jobonly.csv',header=None)\n",
    "tuj.columns = ['job ID','start time', 'end time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              job ID    start time      end time\n",
      "0       3.418314e+06  6.000000e+08  2.506200e+12\n",
      "1       3.418319e+06  6.000000e+08  2.506200e+12\n",
      "2       3.418324e+06  6.000000e+08  2.506200e+12\n",
      "3       3.418329e+06  6.000000e+08  2.506200e+12\n",
      "4       3.418334e+06  6.000000e+08  2.506200e+12\n",
      "...              ...           ...           ...\n",
      "651555  6.486634e+09  2.506141e+12  2.506178e+12\n",
      "651556  6.486634e+09  2.506145e+12  2.506182e+12\n",
      "651557  6.486638e+09  2.506149e+12  2.506187e+12\n",
      "651558  6.486638e+09  2.506155e+12  2.506200e+12\n",
      "651559  6.486641e+09  2.506185e+12  2.506200e+12\n",
      "\n",
      "[651560 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print (tuj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuj['duration'] = tuj['end time'] - tuj['start time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              job ID    start time      end time      duration\n",
      "0       3.418314e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "1       3.418319e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "2       3.418324e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "3       3.418329e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "4       3.418334e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "...              ...           ...           ...           ...\n",
      "651555  6.486634e+09  2.506141e+12  2.506178e+12  3.700000e+07\n",
      "651556  6.486634e+09  2.506145e+12  2.506182e+12  3.700000e+07\n",
      "651557  6.486638e+09  2.506149e+12  2.506187e+12  3.800000e+07\n",
      "651558  6.486638e+09  2.506155e+12  2.506200e+12  4.500000e+07\n",
      "651559  6.486641e+09  2.506185e+12  2.506200e+12  1.500000e+07\n",
      "\n",
      "[651560 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print (tuj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuj.to_csv(\"task_usage_add_duration.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut data (job_ID_name_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_events_type01 = pd.read_csv (r'C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\job_events_type01.csv',header=None,skiprows=1,usecols = [1,2,3,4])\n",
    "job_events_type01.columns = [\"job ID\", \"event type\", \"job scheduling class\", \"job name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID  event type  job scheduling class  \\\n",
      "0           3418314           0                     3   \n",
      "1           3418319           0                     3   \n",
      "2           3418324           0                     3   \n",
      "3           3418329           0                     3   \n",
      "4           3418334           0                     3   \n",
      "...             ...         ...                   ...   \n",
      "1343873  6486638013           1                     1   \n",
      "1343874  6486638079           0                     1   \n",
      "1343875  6486638079           1                     1   \n",
      "1343876  6486641236           0                     0   \n",
      "1343877  6486641236           1                     0   \n",
      "\n",
      "                                             job name  \n",
      "0        L52XDyhi9x9ChmVBZ1qavOFmnzPeVsvQ2QyGmBZcV4s=  \n",
      "1        vq0IN3BWEbkDjYgYvkrVyH6OWoUoDwFFf3j/syEZzLA=  \n",
      "2        X+Vce15Yu3BCKb7Ttc6hvINAzdfG3NtYEDNNsPdMGKo=  \n",
      "3        EeK3DUWYi1P0vgBTp7wZdUos8UKj/+/FqudTLohMQ9M=  \n",
      "4        noCrQkR+8CU32ibuNmNvobHFFGuXRZ2aM/ZvcMHaOg4=  \n",
      "...                                               ...  \n",
      "1343873  hUWYVElFOTQFBOvH8c93V3Z7ASi29Mk9Yg4tc5PCTG4=  \n",
      "1343874  9XfxgqyEqcJEDRFyjlU9D0jaPwhgk3S02Eb/ZyCdD3M=  \n",
      "1343875  9XfxgqyEqcJEDRFyjlU9D0jaPwhgk3S02Eb/ZyCdD3M=  \n",
      "1343876  6cEyQ7YEIiUwugpf7HOg87W3QG7RZOrfzsyOwZwMszw=  \n",
      "1343877  6cEyQ7YEIiUwugpf7HOg87W3QG7RZOrfzsyOwZwMszw=  \n",
      "\n",
      "[1343878 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print (job_events_type01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID                                      job name  \\\n",
      "0           3418314  L52XDyhi9x9ChmVBZ1qavOFmnzPeVsvQ2QyGmBZcV4s=   \n",
      "1           3418319  vq0IN3BWEbkDjYgYvkrVyH6OWoUoDwFFf3j/syEZzLA=   \n",
      "2           3418324  X+Vce15Yu3BCKb7Ttc6hvINAzdfG3NtYEDNNsPdMGKo=   \n",
      "3           3418329  EeK3DUWYi1P0vgBTp7wZdUos8UKj/+/FqudTLohMQ9M=   \n",
      "4           3418334  noCrQkR+8CU32ibuNmNvobHFFGuXRZ2aM/ZvcMHaOg4=   \n",
      "...             ...                                           ...   \n",
      "1343873  6486638013  hUWYVElFOTQFBOvH8c93V3Z7ASi29Mk9Yg4tc5PCTG4=   \n",
      "1343874  6486638079  9XfxgqyEqcJEDRFyjlU9D0jaPwhgk3S02Eb/ZyCdD3M=   \n",
      "1343875  6486638079  9XfxgqyEqcJEDRFyjlU9D0jaPwhgk3S02Eb/ZyCdD3M=   \n",
      "1343876  6486641236  6cEyQ7YEIiUwugpf7HOg87W3QG7RZOrfzsyOwZwMszw=   \n",
      "1343877  6486641236  6cEyQ7YEIiUwugpf7HOg87W3QG7RZOrfzsyOwZwMszw=   \n",
      "\n",
      "         job scheduling class  \n",
      "0                           3  \n",
      "1                           3  \n",
      "2                           3  \n",
      "3                           3  \n",
      "4                           3  \n",
      "...                       ...  \n",
      "1343873                     1  \n",
      "1343874                     1  \n",
      "1343875                     1  \n",
      "1343876                     0  \n",
      "1343877                     0  \n",
      "\n",
      "[1343878 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "job_ID_name_schedule = job_events_type01[['job ID', 'job name', 'job scheduling class']]\n",
    "print (job_ID_name_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ID_name_schedule.to_csv(\"job_ID_name_schedule.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cut data (job_ID_CPU_memory_disk_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.columns = ['job ID', 'task index', 'event type', 'task scheduling class', 'task CPU request', 'task memory request', 'task disk space request']\n",
    "task_events10.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =r\"C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_events\"\n",
    "allFiles = glob.glob(os.path.join(path,\"*.csv\"))\n",
    "\n",
    "np_array_list = []\n",
    "for file_ in allFiles:\n",
    "    df = pd.read_csv(file_,index_col=None, header=0, usecols = [0,4,5,6])\n",
    "    np_array_list.append(df)\n",
    "\n",
    "comb_np_array = np.vstack(np_array_list)\n",
    "task_event = pd.DataFrame(comb_np_array)\n",
    "task_event.columns = ['job ID', 'task CPU request', 'task memory request', 'task disk space request']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                job ID  task CPU request  task memory request  \\\n",
      "0         6.439339e+09            0.0625              0.02386   \n",
      "1         6.439339e+09            0.0625              0.02386   \n",
      "2         6.439339e+09            0.0625              0.02386   \n",
      "3         6.439339e+09            0.0625              0.02386   \n",
      "4         6.439339e+09            0.0625              0.02386   \n",
      "...                ...               ...                  ...   \n",
      "95725671  6.439339e+09            0.0625              0.02386   \n",
      "95725672  6.439339e+09            0.0625              0.02386   \n",
      "95725673  6.439339e+09            0.0625              0.02386   \n",
      "95725674  6.439339e+09            0.0625              0.02386   \n",
      "95725675  6.439339e+09            0.0625              0.02386   \n",
      "\n",
      "          task disk space request  \n",
      "0                        0.000386  \n",
      "1                        0.000386  \n",
      "2                        0.000386  \n",
      "3                        0.000386  \n",
      "4                        0.000386  \n",
      "...                           ...  \n",
      "95725671                 0.000386  \n",
      "95725672                 0.000386  \n",
      "95725673                 0.000386  \n",
      "95725674                 0.000386  \n",
      "95725675                 0.000386  \n",
      "\n",
      "[95725676 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print (task_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_event_1 = task_event.groupby('job ID').sum().reset_index()[['job ID', 'task CPU request', 'task memory request','task disk space request']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              job ID  task CPU request  task memory request  \\\n",
      "0       3.418309e+06           0.50000             0.297840   \n",
      "1       3.418314e+06           0.37500             0.453380   \n",
      "2       3.418319e+06           0.18750             0.521460   \n",
      "3       3.418324e+06           0.37500             0.528780   \n",
      "4       3.418329e+06           1.12500             0.893160   \n",
      "...              ...               ...                  ...   \n",
      "671999  6.486634e+09           0.03124             0.031060   \n",
      "672000  6.486634e+09           0.03124             0.031060   \n",
      "672001  6.486638e+09           0.03124             0.031060   \n",
      "672002  6.486638e+09          25.97994             7.219800   \n",
      "672003  6.486641e+09           0.00000             0.000311   \n",
      "\n",
      "        task disk space request  \n",
      "0                      0.001698  \n",
      "1                      0.002305  \n",
      "2                      0.002729  \n",
      "3                      0.002821  \n",
      "4                      0.009441  \n",
      "...                         ...  \n",
      "671999                 0.000076  \n",
      "672000                 0.000076  \n",
      "672001                 0.000076  \n",
      "672002                 0.175203  \n",
      "672003                 0.000000  \n",
      "\n",
      "[672004 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print (task_event_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_event_1.to_csv(\"job_ID_CPU_memory_disk_request.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ID_name_schedule = pd.read_csv (r'C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\job_ID_name_schedule.csv',header=None)\n",
    "job_ID_name_schedule.columns = ['job ID', 'job name', 'job scheduling class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID                                      job name  \\\n",
      "0           3418314  L52XDyhi9x9ChmVBZ1qavOFmnzPeVsvQ2QyGmBZcV4s=   \n",
      "1           3418319  vq0IN3BWEbkDjYgYvkrVyH6OWoUoDwFFf3j/syEZzLA=   \n",
      "2           3418324  X+Vce15Yu3BCKb7Ttc6hvINAzdfG3NtYEDNNsPdMGKo=   \n",
      "3           3418329  EeK3DUWYi1P0vgBTp7wZdUos8UKj/+/FqudTLohMQ9M=   \n",
      "4           3418334  noCrQkR+8CU32ibuNmNvobHFFGuXRZ2aM/ZvcMHaOg4=   \n",
      "...             ...                                           ...   \n",
      "1343873  6486638013  hUWYVElFOTQFBOvH8c93V3Z7ASi29Mk9Yg4tc5PCTG4=   \n",
      "1343874  6486638079  9XfxgqyEqcJEDRFyjlU9D0jaPwhgk3S02Eb/ZyCdD3M=   \n",
      "1343875  6486638079  9XfxgqyEqcJEDRFyjlU9D0jaPwhgk3S02Eb/ZyCdD3M=   \n",
      "1343876  6486641236  6cEyQ7YEIiUwugpf7HOg87W3QG7RZOrfzsyOwZwMszw=   \n",
      "1343877  6486641236  6cEyQ7YEIiUwugpf7HOg87W3QG7RZOrfzsyOwZwMszw=   \n",
      "\n",
      "         job scheduling class  \n",
      "0                           3  \n",
      "1                           3  \n",
      "2                           3  \n",
      "3                           3  \n",
      "4                           3  \n",
      "...                       ...  \n",
      "1343873                     1  \n",
      "1343874                     1  \n",
      "1343875                     1  \n",
      "1343876                     0  \n",
      "1343877                     0  \n",
      "\n",
      "[1343878 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print (job_ID_name_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             job ID                                      job name  \\\n",
      "0           3418314  L52XDyhi9x9ChmVBZ1qavOFmnzPeVsvQ2QyGmBZcV4s=   \n",
      "1           3418319  vq0IN3BWEbkDjYgYvkrVyH6OWoUoDwFFf3j/syEZzLA=   \n",
      "2           3418324  X+Vce15Yu3BCKb7Ttc6hvINAzdfG3NtYEDNNsPdMGKo=   \n",
      "3           3418329  EeK3DUWYi1P0vgBTp7wZdUos8UKj/+/FqudTLohMQ9M=   \n",
      "4           3418334  noCrQkR+8CU32ibuNmNvobHFFGuXRZ2aM/ZvcMHaOg4=   \n",
      "...             ...                                           ...   \n",
      "1343866  6486631417  9H2yLkZmwR3Zu6rUn27PujSCfp8+8L6KDChhe0v60h0=   \n",
      "1343867  6486631637  w9HpdQ9q4yplyn4JqELkCHHCMxvcXWXENuS6/RrXcL8=   \n",
      "1343872  6486638013  hUWYVElFOTQFBOvH8c93V3Z7ASi29Mk9Yg4tc5PCTG4=   \n",
      "1343874  6486638079  9XfxgqyEqcJEDRFyjlU9D0jaPwhgk3S02Eb/ZyCdD3M=   \n",
      "1343876  6486641236  6cEyQ7YEIiUwugpf7HOg87W3QG7RZOrfzsyOwZwMszw=   \n",
      "\n",
      "         job scheduling class  \n",
      "0                           3  \n",
      "1                           3  \n",
      "2                           3  \n",
      "3                           3  \n",
      "4                           3  \n",
      "...                       ...  \n",
      "1343866                     1  \n",
      "1343867                     1  \n",
      "1343872                     1  \n",
      "1343874                     1  \n",
      "1343876                     0  \n",
      "\n",
      "[672074 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "job_ID_name_schedule.drop_duplicates(keep='first',inplace=True) \n",
    "print (job_ID_name_schedule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ID_name_schedule.to_csv(\"job_ID_name_schedule_drop_duplicates.csv\", header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_ID_CPU_memory_disk_request = pd.read_csv (r'C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\job_ID_CPU_memory_disk_request.csv',header=None)\n",
    "job_ID_CPU_memory_disk_request.columns = ['job ID', 'CPU request', 'memory request','disk space request']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              job ID  CPU request  memory request  disk space request\n",
      "0       3.418309e+06      0.50000        0.297840            0.001698\n",
      "1       3.418314e+06      0.37500        0.453380            0.002305\n",
      "2       3.418319e+06      0.18750        0.521460            0.002729\n",
      "3       3.418324e+06      0.37500        0.528780            0.002821\n",
      "4       3.418329e+06      1.12500        0.893160            0.009441\n",
      "...              ...          ...             ...                 ...\n",
      "671999  6.486634e+09      0.03124        0.031060            0.000076\n",
      "672000  6.486634e+09      0.03124        0.031060            0.000076\n",
      "672001  6.486638e+09      0.03124        0.031060            0.000076\n",
      "672002  6.486638e+09     25.97994        7.219800            0.175203\n",
      "672003  6.486641e+09      0.00000        0.000311            0.000000\n",
      "\n",
      "[672004 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(job_ID_CPU_memory_disk_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_info_request = pd.merge(job_ID_name_schedule, job_ID_CPU_memory_disk_request, on = ['job ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            job ID                                      job name  \\\n",
      "0          3418314  L52XDyhi9x9ChmVBZ1qavOFmnzPeVsvQ2QyGmBZcV4s=   \n",
      "1          3418319  vq0IN3BWEbkDjYgYvkrVyH6OWoUoDwFFf3j/syEZzLA=   \n",
      "2          3418324  X+Vce15Yu3BCKb7Ttc6hvINAzdfG3NtYEDNNsPdMGKo=   \n",
      "3          3418329  EeK3DUWYi1P0vgBTp7wZdUos8UKj/+/FqudTLohMQ9M=   \n",
      "4          3418334  noCrQkR+8CU32ibuNmNvobHFFGuXRZ2aM/ZvcMHaOg4=   \n",
      "...            ...                                           ...   \n",
      "671999  6486631417  9H2yLkZmwR3Zu6rUn27PujSCfp8+8L6KDChhe0v60h0=   \n",
      "672000  6486631637  w9HpdQ9q4yplyn4JqELkCHHCMxvcXWXENuS6/RrXcL8=   \n",
      "672001  6486638013  hUWYVElFOTQFBOvH8c93V3Z7ASi29Mk9Yg4tc5PCTG4=   \n",
      "672002  6486638079  9XfxgqyEqcJEDRFyjlU9D0jaPwhgk3S02Eb/ZyCdD3M=   \n",
      "672003  6486641236  6cEyQ7YEIiUwugpf7HOg87W3QG7RZOrfzsyOwZwMszw=   \n",
      "\n",
      "        job scheduling class  CPU request  memory request  disk space request  \n",
      "0                          3      0.37500        0.453380            0.002305  \n",
      "1                          3      0.18750        0.521460            0.002729  \n",
      "2                          3      0.37500        0.528780            0.002821  \n",
      "3                          3      1.12500        0.893160            0.009441  \n",
      "4                          3      0.12500        0.189700            0.000988  \n",
      "...                      ...          ...             ...                 ...  \n",
      "671999                     1     25.97994        7.219800            0.175203  \n",
      "672000                     1     25.97994        7.219800            0.175203  \n",
      "672001                     1      0.03124        0.031060            0.000076  \n",
      "672002                     1     25.97994        7.219800            0.175203  \n",
      "672003                     0      0.00000        0.000311            0.000000  \n",
      "\n",
      "[672004 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print (job_info_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_info_request.to_csv(\"job_info_request.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# task_usage_add_duration.csv\n",
    "task_usage_add_duration = pd.read_csv (r'C:\\Users\\Qinghua\\Desktop\\2\\111AAAProject\\task_usage_add_duration.csv',header=None)\n",
    "task_usage_add_duration.columns = ['job ID','start time', 'end time', 'duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              job ID    start time      end time      duration\n",
      "0       3.418314e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "1       3.418319e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "2       3.418324e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "3       3.418329e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "4       3.418334e+06  6.000000e+08  2.506200e+12  2.505600e+12\n",
      "...              ...           ...           ...           ...\n",
      "651555  6.486634e+09  2.506141e+12  2.506178e+12  3.700000e+07\n",
      "651556  6.486634e+09  2.506145e+12  2.506182e+12  3.700000e+07\n",
      "651557  6.486638e+09  2.506149e+12  2.506187e+12  3.800000e+07\n",
      "651558  6.486638e+09  2.506155e+12  2.506200e+12  4.500000e+07\n",
      "651559  6.486641e+09  2.506185e+12  2.506200e+12  1.500000e+07\n",
      "\n",
      "[651560 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print (task_usage_add_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            job ID                                      job name  \\\n",
      "0          3418314  L52XDyhi9x9ChmVBZ1qavOFmnzPeVsvQ2QyGmBZcV4s=   \n",
      "1          3418319  vq0IN3BWEbkDjYgYvkrVyH6OWoUoDwFFf3j/syEZzLA=   \n",
      "2          3418324  X+Vce15Yu3BCKb7Ttc6hvINAzdfG3NtYEDNNsPdMGKo=   \n",
      "3          3418329  EeK3DUWYi1P0vgBTp7wZdUos8UKj/+/FqudTLohMQ9M=   \n",
      "4          3418334  noCrQkR+8CU32ibuNmNvobHFFGuXRZ2aM/ZvcMHaOg4=   \n",
      "...            ...                                           ...   \n",
      "651555  6486631417  9H2yLkZmwR3Zu6rUn27PujSCfp8+8L6KDChhe0v60h0=   \n",
      "651556  6486631637  w9HpdQ9q4yplyn4JqELkCHHCMxvcXWXENuS6/RrXcL8=   \n",
      "651557  6486638013  hUWYVElFOTQFBOvH8c93V3Z7ASi29Mk9Yg4tc5PCTG4=   \n",
      "651558  6486638079  9XfxgqyEqcJEDRFyjlU9D0jaPwhgk3S02Eb/ZyCdD3M=   \n",
      "651559  6486641236  6cEyQ7YEIiUwugpf7HOg87W3QG7RZOrfzsyOwZwMszw=   \n",
      "\n",
      "        job scheduling class  CPU request  memory request  disk space request  \\\n",
      "0                          3      0.37500        0.453380            0.002305   \n",
      "1                          3      0.18750        0.521460            0.002729   \n",
      "2                          3      0.37500        0.528780            0.002821   \n",
      "3                          3      1.12500        0.893160            0.009441   \n",
      "4                          3      0.12500        0.189700            0.000988   \n",
      "...                      ...          ...             ...                 ...   \n",
      "651555                     1     25.97994        7.219800            0.175203   \n",
      "651556                     1     25.97994        7.219800            0.175203   \n",
      "651557                     1      0.03124        0.031060            0.000076   \n",
      "651558                     1     25.97994        7.219800            0.175203   \n",
      "651559                     0      0.00000        0.000311            0.000000   \n",
      "\n",
      "          start time      end time      duration  \n",
      "0       6.000000e+08  2.506200e+12  2.505600e+12  \n",
      "1       6.000000e+08  2.506200e+12  2.505600e+12  \n",
      "2       6.000000e+08  2.506200e+12  2.505600e+12  \n",
      "3       6.000000e+08  2.506200e+12  2.505600e+12  \n",
      "4       6.000000e+08  2.506200e+12  2.505600e+12  \n",
      "...              ...           ...           ...  \n",
      "651555  2.506139e+12  2.506200e+12  6.100000e+07  \n",
      "651556  2.506139e+12  2.506200e+12  6.100000e+07  \n",
      "651557  2.506149e+12  2.506187e+12  3.800000e+07  \n",
      "651558  2.506155e+12  2.506200e+12  4.500000e+07  \n",
      "651559  2.506185e+12  2.506200e+12  1.500000e+07  \n",
      "\n",
      "[651560 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "job_merge_all = pd.merge(job_info_request, task_usage_add_duration, on = ['job ID'])\n",
    "print (job_merge_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_merge_all.to_csv(\"job_merge_all.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
